# Machine-Learning-Stanford

We are gaving two Course Together here Old Version and New Version Both

[Old Link Videos](https://www.youtube.com/watch?v=gb262LDH1So&list=PLiPvV5TNogxIS4bHQVW4pMkj4CHA8COdX)

[Old PPT](https://github.com/vkosuri/CourseraMachineLearning/)

[New PPT](https://github.com/LasithaAmarasinghe/Machine-Learning-Specialization-Coursera/)

Some Highlihs to Remember:
- Reference --> Week 1 : Gradient descent intuition (Look Slides)
- Derivative(cost Fucntion) with respect to Weight
  - Decrease value of weight increase Cost so Derivative is --> Negative
  - Decrease value of weight Decrease Cost so Derivative is --> Positive
  - Weight = Weight - alpha (derivative Result) --> equation --> Achieve our desire Aim
  - Links to Understand [Derivative](https://www.mathway.com/examples/calculus/derivatives/using-the-limit-definition-to-find-the-derivative?id=665)


 - Gradient descent finds Local Minimum
 - Varability in Learning Rate
   - The quantity of derivative will tell us learning rate steps with fixed value
  



